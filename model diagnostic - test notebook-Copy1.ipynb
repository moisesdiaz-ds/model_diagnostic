{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11aab45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_diagnostic_utils as md\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1d8ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Titanic_train.csv')\n",
    "\n",
    "df = pd.get_dummies(df,columns=['Sex'])\n",
    "features = ['Pclass','Age','Sex_female','Fare']\n",
    "target = 'Survived'\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.reset_index(drop=True), y.reset_index(drop=True), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70965fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_results_files = 'results_files'\n",
    "dir_models = 'models'\n",
    "\n",
    "model_id = 'Your_user_name-21213528'\n",
    "model_id2 = 'Your_user_name-21213533'\n",
    "\n",
    "umbral_elegido = 0.5\n",
    "umbral_elegido2 = 0.5\n",
    "\n",
    "limit_imp = 5\n",
    "\n",
    "model_name = 'Model 1'\n",
    "model_name2 = 'Model 2'\n",
    "\n",
    "data_for_comparison = df[list(X_train.columns)+[target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4710613c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9d4181a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:42:37] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:1203: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[11:42:37] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:888: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[11:42:37] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[11:42:37] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:1203: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[11:42:37] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:888: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[11:42:37] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "\n",
      "===== Mostrando Las metricas del modelo\n",
      "\n",
      "=== Model 1\n",
      "Tipo_metrica          Clasificacion\n",
      "Tipo_modelo                       1\n",
      "Algoritmo             XGBClassifier\n",
      "umbral                          0.5\n",
      "AUC                        0.841667\n",
      "Gini                       0.683333\n",
      "PRAUC                           NaN\n",
      "F1_score                   0.761797\n",
      "Accuracy                   0.772881\n",
      "Recall                     0.762738\n",
      "Precision                  0.765568\n",
      "Fecha           2023-02-21 21:35:00\n",
      "Comentario                      NaN\n",
      "Name: Your_user_name-21213528, dtype: object\n",
      "\n",
      "== Confusion matrix\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'XGBModel' object has no attribute 'callbacks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dicc_return \u001b[38;5;241m=\u001b[39m \u001b[43mmd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_diagnostic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdir_results_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdir_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodel_id2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mumbral_elegido\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mumbral_elegido2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mlimit_imp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodel_name2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_for_comparison\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mporcentaje_df_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mexisting_shap_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mexisting_df_shap_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mexisting_shap_values_df_compare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mexisting_df_shap_values_df_compare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtruncate_out\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mskew_validation_out_shap\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                    \u001b[49m\u001b[43muse_normal_shap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msample_size_local_shap\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mspecific_rows_local_shap\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mreturn_model_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mreturn_feature_importance_gini\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mreturn_model_calibration_curve\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mreturn_compare_data_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mreturn_performance_by_segment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mreturn_profiling_false_negatives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mreturn_shap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mreturn_shap_df_compare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mreturn_feature_importance_by_perm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Dropbox\\GitHub dropbox\\Scripts_Python\\model_diagnostic_clean\\model_diagnostic\\model_diagnostic_utils.py:1272\u001b[0m, in \u001b[0;36mmodel_diagnostic\u001b[1;34m(X_train, y_train, X_test, y_test, target, dir_results_files, dir_models, model_id, model_id2, umbral_elegido, umbral_elegido2, limit_imp, model_name, model_name2, data_for_comparison, porcentaje_df_sample, existing_shap_values, existing_df_shap_values, existing_shap_values_df_compare, existing_df_shap_values_df_compare, truncate_out, skew_validation_out_shap, use_normal_shap, sample_size_local_shap, specific_rows_local_shap, return_model_metrics, return_feature_importance_gini, return_model_calibration_curve, return_compare_data_dist, return_performance_by_segment, return_profiling_false_negatives, return_shap, return_shap_df_compare, return_feature_importance_by_perm)\u001b[0m\n\u001b[0;32m   1270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_model_metrics:\n\u001b[0;32m   1271\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m===== Mostrando Las metricas del modelo\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1272\u001b[0m     \u001b[43mmodel_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchosen_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfeatures2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchosen_model2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_id2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_name2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mumbral_elegido\u001b[49m\u001b[43m,\u001b[49m\u001b[43mumbral_elegido2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_feature_importance_gini:\n\u001b[0;32m   1275\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m===== Mostrando el feature importance by gini\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Dropbox\\GitHub dropbox\\Scripts_Python\\model_diagnostic_clean\\model_diagnostic\\model_diagnostic_utils.py:62\u001b[0m, in \u001b[0;36mmodel_metrics\u001b[1;34m(df_results, X_test, y_test, features, chosen_model, features2, chosen_model2, target, model_id, model_id2, model_name, model_name2, umbral_elegido, umbral_elegido2)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m== Confusion matrix\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m \u001b[43mget_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mumbral_elegido\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchosen_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mloc[model_id2])\n",
      "File \u001b[1;32m~\\Dropbox\\GitHub dropbox\\Scripts_Python\\model_diagnostic_clean\\model_diagnostic\\model_diagnostic_utils.py:39\u001b[0m, in \u001b[0;36mget_confusion_matrix\u001b[1;34m(umbral_elegido, X_test, y_test, features, chosen_model, target)\u001b[0m\n\u001b[0;32m     37\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m     38\u001b[0m df[target] \u001b[38;5;241m=\u001b[39m y_test[target]\n\u001b[1;32m---> 39\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_proba\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mchosen_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     40\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_proba\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39mumbral_elegido\n\u001b[0;32m     42\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\diagnostic_env\\lib\\site-packages\\xgboost\\sklearn.py:1606\u001b[0m, in \u001b[0;36mXGBClassifier.predict_proba\u001b[1;34m(self, X, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1604\u001b[0m     class_prob \u001b[38;5;241m=\u001b[39m softmax(raw_predt, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m class_prob\n\u001b[1;32m-> 1606\u001b[0m class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mntree_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mntree_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1612\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;66;03m# If model is loaded from a raw booster there's no `n_classes_`\u001b[39;00m\n\u001b[0;32m   1614\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _cls_predict_proba(\n\u001b[0;32m   1615\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_classes_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m), class_probs, np\u001b[38;5;241m.\u001b[39mvstack\n\u001b[0;32m   1616\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\diagnostic_env\\lib\\site-packages\\xgboost\\sklearn.py:1112\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1108\u001b[0m iteration_range \u001b[38;5;241m=\u001b[39m _convert_ntree_limit(\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_booster(), ntree_limit, iteration_range\n\u001b[0;32m   1110\u001b[0m )\n\u001b[0;32m   1111\u001b[0m iteration_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iteration_range(iteration_range)\n\u001b[1;32m-> 1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_can_use_inplace_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1114\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_booster()\u001b[38;5;241m.\u001b[39minplace_predict(\n\u001b[0;32m   1115\u001b[0m             data\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1116\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1120\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1121\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\diagnostic_env\\lib\\site-packages\\xgboost\\sklearn.py:1047\u001b[0m, in \u001b[0;36mXGBModel._can_use_inplace_predict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_can_use_inplace_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m   1043\u001b[0m     \u001b[38;5;66;03m# When predictor is explicitly set, using `inplace_predict` might result into\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;66;03m# error with incompatible data type.\u001b[39;00m\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# Inplace predict doesn't handle as many data types as DMatrix, but it's\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;66;03m# sufficient for dask interface where input is simpiler.\u001b[39;00m\n\u001b[1;32m-> 1047\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_xgb_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1048\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m predictor \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooster \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1049\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\diagnostic_env\\lib\\site-packages\\xgboost\\sklearn.py:708\u001b[0m, in \u001b[0;36mXGBModel.get_xgb_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_xgb_params\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    707\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get xgboost specific parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m     params: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    710\u001b[0m     \u001b[38;5;66;03m# Parameters that should not go into native learner.\u001b[39;00m\n\u001b[0;32m    711\u001b[0m     wrapper_specific \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    712\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimportance_type\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    713\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    720\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_types\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    721\u001b[0m     }\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\diagnostic_env\\lib\\site-packages\\xgboost\\sklearn.py:695\u001b[0m, in \u001b[0;36mXGBModel.get_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    693\u001b[0m cp \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    694\u001b[0m cp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__bases__\u001b[39m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 695\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    696\u001b[0m \u001b[38;5;66;03m# if kwargs is a dict, update params accordingly\u001b[39;00m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\diagnostic_env\\lib\\site-packages\\xgboost\\sklearn.py:692\u001b[0m, in \u001b[0;36mXGBModel.get_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get parameters.\"\"\"\u001b[39;00m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;66;03m# Based on: https://stackoverflow.com/questions/59248211\u001b[39;00m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;66;03m# The basic flow in `get_params` is:\u001b[39;00m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;66;03m# 0. Return parameters in subclass first, by using inspect.\u001b[39;00m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;66;03m# 1. Return parameters in `XGBModel` (the base class).\u001b[39;00m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;66;03m# 2. Return whatever in `**kwargs`.\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;66;03m# 3. Merge them.\u001b[39;00m\n\u001b[1;32m--> 692\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    693\u001b[0m cp \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    694\u001b[0m cp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__bases__\u001b[39m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\diagnostic_env\\lib\\site-packages\\sklearn\\base.py:170\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    168\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names():\n\u001b[1;32m--> 170\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m    172\u001b[0m         deep_items \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mget_params()\u001b[38;5;241m.\u001b[39mitems()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'XGBModel' object has no attribute 'callbacks'"
     ]
    }
   ],
   "source": [
    "dicc_return = md.model_diagnostic(X_train,\n",
    "                    y_train,\n",
    "                    X_test,\n",
    "                    y_test,\n",
    "                    target,\n",
    "                    dir_results_files,\n",
    "                    dir_models,\n",
    "                    model_id,\n",
    "                    model_id2,\n",
    "                    umbral_elegido,\n",
    "                    umbral_elegido2,\n",
    "                    limit_imp,\n",
    "                    model_name,\n",
    "                    model_name2,\n",
    "                    data_for_comparison,\n",
    "                    porcentaje_df_sample=0.7,\n",
    "                    existing_shap_values=None,\n",
    "                    existing_df_shap_values=None,\n",
    "                    existing_shap_values_df_compare=None,\n",
    "                    existing_df_shap_values_df_compare=None,\n",
    "                    truncate_out = 1,\n",
    "                    skew_validation_out_shap = 0,\n",
    "                    use_normal_shap=0,\n",
    "                    sample_size_local_shap = 6,\n",
    "                    specific_rows_local_shap = [0,1,2,3,4,5],\n",
    "                    return_model_metrics=1,\n",
    "                    return_feature_importance_gini=1,\n",
    "                    return_model_calibration_curve=1,\n",
    "                    return_compare_data_dist=1,\n",
    "                    return_performance_by_segment=0,\n",
    "                    return_profiling_false_negatives=0,\n",
    "                    return_shap=1,\n",
    "                    return_shap_df_compare=0,\n",
    "                    return_feature_importance_by_perm=0,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182a63db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152898da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3602525b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b1a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ef7239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3ef52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
